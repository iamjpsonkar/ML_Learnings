{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Multiple Linear Regression\n",
    "If there are multiple variables inside Linear Regression Equation, it is known as Multiple Linear Regression\n",
    "Let's see equation\n",
    "$$ y = b_{0} \\ \\ + \\ \\ b_{1}x_{1}  \\ \\ + \\ \\ b_{2}x_{2}  \\ \\ + \\ \\ b_{3}x_{3} \\ \\ + \\ \\ ... \\ \\ + \\ \\ b_{n}x_{n} $$\n",
    "Now y will depend on multiple values, we can still predict/calculate value of y, if we have the equation and the values of the X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions of Linear Regression\n",
    "There are 5 assumptions\n",
    "1. Linearity\n",
    "2. Homoscedasticity\n",
    "3. Multivariate Normality\n",
    "4. Independence of Errors\n",
    "5. Lack of Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hypothesis Testing (P-Value)\n",
    "Supose you have a coin, and you are tossing it continiously\n",
    "1. got HEAD, its probability is 0.5\n",
    "2. got again HEAD, its probability is 0.25\n",
    "3. got again HEAD, its probability is 0.12\n",
    "4. got again HEAD, its probability is 0.06\n",
    "\n",
    "If you get get HEAD again (probability 0.03), coin is suspicous. you may think coin is not a fair coin.\\\n",
    "The point/percent at which you become suspicious is known as **Significance Value**.\\\n",
    "Initially we assume coin is fair, but when the significance value is reached, we correct our assumption (Hypothesis) and confirm that it is not a fair coin, this is known as **Null Hypothesis Testing**.\n",
    "\n",
    "## Building a Multiple Linear Regression Model\n",
    "There are 5 ways to build Multiple Linear Regression Model\n",
    "1. All In\n",
    ":  Select all the columns\n",
    "    - You have prior knowledge\n",
    "    - You have to select all columns\n",
    "    - You are preparing for backward elimination\n",
    "2. Backward Elimination (Fastest)\n",
    "    1. Select a Significance Level to stay in the model (SL=0.05)\n",
    "    2. Fit the model with all columns/predictor\n",
    "    3. Select the column/predictor with highest P-Value, if P-Value > SL goto step 4, else go to FINISH\n",
    "    4. Remove the predictor\n",
    "    5. Fit the model again, and go to step 3\n",
    "3. Forward Selection\n",
    "    1. Select a Significance Level to Enter in the model (SL=0.05)\n",
    "    2. Fit the model with all predictors seperately\n",
    "    3. Select the predictor with lowest P-value, if P-value < SL goto step 4, else FINISH and keep the last model\n",
    "    4. Fit the model, using all the remaining predictors separately and with this one extra combination\n",
    "4. Bidirection Elemination\n",
    "    1. Select a Significance Level to stay in the model (STAY_SL=0.05) and a Significance Level to Enter in the model (ENTER_SL=0.05)\n",
    "    2. Perform next step of Forward Selection\n",
    "    3. Perform all step of Backward Elimination\n",
    "    4. When no new predictors enter and no old predictors can exit, FINISH\n",
    "5. Score Comparision\n",
    "    1. Select a criterion of goodness (Score)\n",
    "    2. Construct all possible regression model (2<sup>N</sup>-1)\n",
    "    3. Select the best model using goodness criterion\n",
    "    4. FINISH\n",
    "\n",
    "Step-wise Regression\n",
    "- Backward Elimination\n",
    "- Forward Selection\n",
    "- Bidirection Elemination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('./Datasets/50_Startups.csv')\n",
    "# print(dataset)\n",
    "\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n",
    "# Taking care of Missing values\n",
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:,:-1])\n",
    "X[:,:-1] =  imputer.transform(X[:,:-1])\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer.fit(X[:,-2:-1])\n",
    "X[:,-2:-1] =  imputer.transform(X[:,-2:-1])\n",
    "# print(X)\n",
    "\n",
    "# Encoding categorial Data [One Hot Encoding]\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encode',OneHotEncoder(),[-1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "# print(X)\n",
    "\n",
    "# Splitting dataset into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Linear Regression Model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the result for test set result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the predicted and actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114664.42 105008.31]\n",
      " [ 90593.16  96479.51]\n",
      " [ 75692.84  78239.91]\n",
      " [ 70221.89  81229.06]\n",
      " [179790.26 191050.39]\n",
      " [171576.92 182901.99]\n",
      " [ 49753.59  35673.41]\n",
      " [102276.66 101004.64]\n",
      " [ 58649.38  49490.75]\n",
      " [ 98272.03  97483.56]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the equation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 49834.88507320514 + 49549.7073037427*x1 + 50132.44594966615*x2 + 49822.5019662015*x3 + 49835.65941528625*x4 + 49834.87562950929*x5 + 49834.91399151843*x6\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train[0])\n",
    "b0=regressor.predict([[0 for _ in range(n)]])\n",
    "eq=\"y = {}\".format(b0[0])\n",
    "for i in range(n):\n",
    "    eq+=\" + {}*x{}\".format(regressor.predict([[0 for _ in range(i)]+[1]+[0 for _ in range(i+1,n)]])[0],i+1)\n",
    "print(eq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mlvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "321334cedfa16b8be24125e5ab0e3623912f69d4b899407428e8bc07c2d3a5b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
